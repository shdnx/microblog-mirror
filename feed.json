{
	"version": "https://jsonfeed.org/version/1",
	"title": "The Stargazer",
	"icon": "https://micro.blog/shdnx/avatar.jpg",
	"home_page_url": "https://blog.gaborkozar.me/",
	"feed_url": "https://blog.gaborkozar.me/feed.json",
	"items": [
		
			{
				"id": "http://shdnx.micro.blog/2023/07/22/financial-news-and.html",
				"title": "Financial news and moving the markets",
				"content_html": "<p>Daring Fireball wrote about the <a href=\"https://daringfireball.net/2023/07/apple_gpt_bloomberg\">Apple GPT news</a>. I think the news itself is pretty uninteresting: Apple wants in on the ChatGPT gold-rush even as it seems to be winding down. The more interesting part is what he writes about Bloomberg:</p>\n<blockquote>\n<p>Bloomberg reporters are evaluated and receive bonuses tied to reporting market-moving news. They’re incentivized financially to make mountains out of molehills, and craters out of divots, to maximize the immediate effect of their reporting on stock prices. And Bloomberg appends these stock price movements right there in their reports, to drive home the notion that Bloomberg publishes market-moving news, so maybe you too should spend over $2,000 per month on a Bloomberg Terminal so that you can receive news reports from Bloomberg minutes before the general public, and buy, sell, and short stocks based on that news.\n&hellip;\nApple’s brief 2.7 percent jump and Microsoft’s smaller but still-significant drop, both at 12:04pm, were clearly caused by Gurman’s report. Bloomberg Terminal subscribers get such reports before anyone else. [&hellip;] most of their original reporting is delivered with the goal of moving the stock prices of the companies they’re reporting on, for the purpose of proving the value of a Bloomberg Terminal’s hefty subscription fee to day-trading gamblers [&hellip;]</p>\n</blockquote>\n<p>Tinfoil hat time? I mean&hellip; that&rsquo;s quite the stretch. Even if Bloomberg doesn&rsquo;t report particular news, a million other websites will; how does Bloomberg move the market in particular?\nBloomberg is hardly the only company selling ahead-of-the-crowd services; it&rsquo;s obviously a lucrative thing to do successfully, given the herd mentality that all markets follow<sup id=\"fnref:1\"><a href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\">1</a></sup>.\nThey obviously want to communicate news that have <em>the potential</em> of moving stocks, otherwise they&rsquo;d not be a good source of finance news!</p>\n<p>As for making mountains out of molehills, I think that&rsquo;s a fair criticism to an extent, but it&rsquo;s also not one that is in any way unique to Bloomberg. Clickbait and blowing news out of proportion is just business as usual for mass media these days, thanks to the advertising industry financing a large chunk of websites and competition <a href=\"https://slatestarcodex.com/2014/07/30/meditations-on-moloch/\">fierce enough to trigger</a> a race to the bottom with low-effort reporting. My personal impression is that Bloomberg is actually better than many in this regard.</p>\n<p>By the way, the Apple stock <em>stayed up</em> after these news (see the <a href=\"https://www.investing.com/equities/apple-computer-inc\">Investing.com chart</a>), only dropping back to previous levels some 24 hours later when manufacturing issues were reported with the upcoming iPhone 15. So it was <em>good reporting</em> by Bloomberg.</p>\n<!-- raw HTML omitted -->\n<section class=\"footnotes\" role=\"doc-endnotes\">\n<hr>\n<ol>\n<li id=\"fn:1\" role=\"doc-endnote\">\n<p>Predicting how a market will move though is pretty much hopeless in the general case, as financial markets are a good example of a chaotic system in that it responds not just to events, but predictions and expectations as well, and does so in a recursive, self-predicting way: if enough people think that upon some news others will want to buy a particular stock, then the stock will move on the news. This is one of the factors that makes markets very &ldquo;noisy&rdquo;: prices move very frequently, even for large, fairly stable stocks.&#160;<a href=\"#fnref:1\" class=\"footnote-backref\" role=\"doc-backlink\">&#x21a9;&#xfe0e;</a></p>\n</li>\n</ol>\n</section>\n",
				"content_text": "Daring Fireball wrote about the [Apple GPT news](https://daringfireball.net/2023/07/apple_gpt_bloomberg). I think the news itself is pretty uninteresting: Apple wants in on the ChatGPT gold-rush even as it seems to be winding down. The more interesting part is what he writes about Bloomberg:\r\n\r\n> Bloomberg reporters are evaluated and receive bonuses tied to reporting market-moving news. They’re incentivized financially to make mountains out of molehills, and craters out of divots, to maximize the immediate effect of their reporting on stock prices. And Bloomberg appends these stock price movements right there in their reports, to drive home the notion that Bloomberg publishes market-moving news, so maybe you too should spend over $2,000 per month on a Bloomberg Terminal so that you can receive news reports from Bloomberg minutes before the general public, and buy, sell, and short stocks based on that news.\r\n> ...\r\n> Apple’s brief 2.7 percent jump and Microsoft’s smaller but still-significant drop, both at 12:04pm, were clearly caused by Gurman’s report. Bloomberg Terminal subscribers get such reports before anyone else. [...] most of their original reporting is delivered with the goal of moving the stock prices of the companies they’re reporting on, for the purpose of proving the value of a Bloomberg Terminal’s hefty subscription fee to day-trading gamblers [...]\r\n\r\nTinfoil hat time? I mean... that's quite the stretch. Even if Bloomberg doesn't report particular news, a million other websites will; how does Bloomberg move the market in particular?\r\nBloomberg is hardly the only company selling ahead-of-the-crowd services; it's obviously a lucrative thing to do successfully, given the herd mentality that all markets follow[^predicting-markets].\r\nThey obviously want to communicate news that have _the potential_ of moving stocks, otherwise they'd not be a good source of finance news!\r\n\r\nAs for making mountains out of molehills, I think that's a fair criticism to an extent, but it's also not one that is in any way unique to Bloomberg. Clickbait and blowing news out of proportion is just business as usual for mass media these days, thanks to the advertising industry financing a large chunk of websites and competition [fierce enough to trigger](https://slatestarcodex.com/2014/07/30/meditations-on-moloch/) a race to the bottom with low-effort reporting. My personal impression is that Bloomberg is actually better than many in this regard.\r\n\r\nBy the way, the Apple stock _stayed up_ after these news (see the [Investing.com chart](https://www.investing.com/equities/apple-computer-inc)), only dropping back to previous levels some 24 hours later when manufacturing issues were reported with the upcoming iPhone 15. So it was _good reporting_ by Bloomberg.\r\n\r\n[^predicting-markets]: Predicting how a market will move though is pretty much hopeless in the general case, as financial markets are a good example of a chaotic system in that it responds not just to events, but predictions and expectations as well, and does so in a recursive, self-predicting way: if enough people think that upon some news others will want to buy a particular stock, then the stock will move on the news. This is one of the factors that makes markets very \"noisy\": prices move very frequently, even for large, fairly stable stocks.\n\n<img src=\"uploads/2023/aapl-stock-news.png\" width=\"600\" height=\"330\" alt=\"\">\n",
				"date_published": "2023-07-22T01:25:19+02:00",
				"url": "https://blog.gaborkozar.me/2023/07/22/financial-news-and.html"
			},
			{
				"id": "http://shdnx.micro.blog/2023/07/15/outofmemory-while-trying.html",
				"title": "Out-of-memory while trying to free it: into virtual memory",
				"content_html": "<p>I recently came by this fun story on getting an out-of-memory error on Linux when trying to <em>free</em> memory: <a href=\"https://ayende.com/blog/199649-B/production-postmortem-enomem-when-trying-to-free-memory?Key=c9261116-c324-4280-a1e1-35da0d1fa882\">Production postmortem: ENOMEM when trying to free memory</a></p>\n<blockquote>\n<p>That error made absolutely no sense, as you can imagine. We are trying to release memory, not allocate it. Common sense says that you can’t really fail when you are freeing memory. After all, how can you run out of memory? I’m trying to give you some, damn it!</p>\n</blockquote>\n<p>The linked blog post does a good job of explaining the problem briefly and clearly, so I&rsquo;m just going to provide some further context on how this can indeed be a problem.</p>\n<p>Modern computer architectures like x86-64 and even most (all?) the ARMs have a lot funkier relationship with memory than most people &ndash; and even most software developers! &ndash; tend to be aware of. (This is a good thing! You don&rsquo;t need to know how to sausage is made. Abstraction is an invaluable tool for managing complexity.)</p>\n<p>The memory that a running application (any running application) sees and lives in (where it loads all of its data and where all of its allocations live) is actually not a direct representation of the main memory of the computer (the RAM sticks). It used to be, long ago, but we&rsquo;ve moved away from that. Instead, what your process is interacting with is called <em>virtual memory</em>, or more specifically, a <em>virtual memory address-space</em>. Virtual memory is a layer of abstraction on top of <em>physical memory</em>, a decoupling useful because it grants additional performance, stability, and safety. How?</p>\n<p>A process&rsquo;s virtual memory address-space is constructed specifically for that one particular process, and reflects <em>only</em> the parts of the physical memory that are used by it. Memory used by other processes is normally not visible here: it is simply not mapped (outside of special cases like shared memory created by <a href=\"https://man7.org/linux/man-pages/man3/shm_open.3.html\"><code>shm_open()</code></a> and friends or debugging via <a href=\"https://man7.org/linux/man-pages/man2/ptrace.2.html\"><code>ptrace()</code></a>). This means that, by default, no process can accidentally or maliciously access the memory of other processes and extract secrets from it or change the values in unexpected ways leading to erratic behaviour or crashes.</p>\n<p>This layer of abstraction also enables other useful features that reduce overall memory usage at the expense of runtime performance:</p>\n<ul>\n<li>Demand-paging: memory allocated but not yet accessed doesn&rsquo;t actually need to be available: if the application decided to allocate a gigantic 2 GB buffer but hasn&rsquo;t yet used more than 100 KB of it, then the rest doesn&rsquo;t have to be available</li>\n<li>Swapping: rarely used regions of memory are written to disk, and the memory it was used for is made available for new allocations</li>\n<li>Compression: rarely used regions of memory are compressed, and the space freed up is reclaimed for other purposes</li>\n<li>De-duplication: if there are multiple identical copies of the sequence of bytes in memory, we don&rsquo;t actually need to store it multiple times (though caveats apply!)</li>\n</ul>\n<p>For any physical memory to be accessible in a virtual memory address space, it has to be mapped in, typically by the operating system kernel. This is done by writing into a data structure called the <em>page table</em>, which is shared between the kernel and the CPU&rsquo;s memory management unit (MMU). A <em>page table entry</em> typically represents the mapping of some physical memory region into a virtual memory address space: in this case, the entry will contain the physical memory address that it corresponds to. You may have multiple page table entries refer to the same or overlapping regions of physical memory: that is totally cool and allowed! (This has some very interesting uses e.g. in cybersecurity that I wrote <a href=\"https://github.com/shdnx/dangless-malloc\">my Master&rsquo;s thesis on</a>.)</p>\n<p>A page table entry, beyond the physical memory address, also contains bits used for purposes. Some of these are used for protection, to indicate whether the region is readable, writable, or executable. This is enforced by the MMU: attempting to write to a virtual memory region whose page table entry does not have the writable bit set will fail (well, it will trigger a page fault, which can be handled &ndash; more on this later). For example, after a running application&rsquo;s executable is loaded into memory at startup, the region is marked as non-writable (but readable and executable) to prevent buggy software from accidentally modifying its own code and also to limit the options of malware. Similarly, memory regions where the application&rsquo;s runtime data is stored (so the stack, the heap, but also the .data, .bss, and .rodata sections containing global variables) are marked as non-executable, as that is a very easy attack vector for malicious users.  (They can be made executable, otherwise things like Jit-in-Time compilers would not work, but you have to explicitly request it. e.g. on Linux by using <code>mmap()</code> with <code>PROT_EXEC</code>.)</p>\n<p>The page table entry also contains a &ldquo;dirty&rdquo; bit. This is set the MMU whenever that particular memory region is used. The kernel can periodically clear this bit, and then check later if the bit is set: if not, then the corresponding memory region has not been used recently, and so may be candidate to be swapped out or compressed.</p>\n<p>We need a mechanism though for detecting when e.g. a swapped-out piece of memory is accessed. Clearly, such an access cannot simply proceed as normal: the page table entry is marked as invalid, there is no physical memory backing it. The MMU will trigger a <em>page fault</em> in this case, which is an interrupt that the kernel handles. The kernel will consult its own internal book-keeping of the process&rsquo;s memory and will find in this case that it has decided to swap the memory to disk: now, since the data is requested, the data must be loaded back from disk into main memory and the page table entry must be made valid again. Once this is done, the process resumes execution from the exact same place as it was left suspended when trying to access swapped memory, none the wiser to what happened in the background &ndash; except perhaps that some operation ending up having taken much more time than usual.</p>\n<p>This pattern is actually very common, and is used for all of the memory-use optimizations I&rsquo;ve mentioned so far. For instance, in the case of memory de-duplication, identical memory regions may be referenced by multiple processes at the same time. So long as they all only read from it, life is good, but  when one of them wants to write to it, the kernel needs to intervene, as the write would make the memory region no longer contain what the other processes expect it to. This is achieved by marking the page table entries as non-writeable, such that attempting to write results in a page fault. On such page  fault, the kernel quietly duplicates the memory region (by allocating a new one and then copying into it) and updates the writing process&rsquo;s page table entry to point to the new address, restoring its writeability before returning control to the process.</p>\n<p>You may have noticed that I was talking about individual bits of the page table entry. Indeed, these entries are extremely limited in size: typically just 64 bits (8 bytes), most of which is needed to store the referenced physical memory address. This is not always enough for more complicated features built on top of the virtual memory abstraction, so the kernel has additional book-keeping: in Linux, these are called <em>virtual memory areas</em> or VMAs for short: one for each distinct memory region of each running process. For reasons of simplicity and performance, these VMAs are stored in a large pre-allocated array with a fixed capacity.</p>\n<p>This takes us back to the blog post that motivated this write-up: freeing or de-allocating memory may require an additional VMA to be allocated in the case where you&rsquo;re not freeing an entire allocated memory region, but only a part of it. This is not possible to do via the commonly used <code>malloc()</code> / <code>free()</code> APIs or even the C++ <code>new</code> and <code>delete</code> equivalent operators, but it is possible to do via direct system calls using <code>mmap()</code> and <code>munmap()</code>. To illustrate:</p>\n<ol>\n<li>We allocate 1000 bytes of memory</li>\n<li>Linux creates a new VMA for us to record this (note: no actual memory has been allocated unless you used <code>MAP_POPULATE</code> as demand paging kicks in!)</li>\n<li>We now wish to free the middle 500 bytes</li>\n<li>Linux now has no choice but to split the original one VMA spanning 1000 bytes into two of 250 bytes each, with a 500 byte gap in the middle</li>\n</ol>\n<p>Granted, this is a bit contrived, and not even accurate as you cannot free 500 bytes: memory is split into pages of 4096 bytes (4 KB) each (by default, on x86-64). But you can imagine the same situation happening when e.g. different protection bits are applied to different parts of a huge memory region: some part of writeable, other parts are not. The VMA having to be split causes the memory deallocation operation to actually have to allocate memory: for the new VMA. This is how you can get an out-of-memory error.</p>\n<p>As you can imagine, there are a lot more details to this topic. Some teasers:</p>\n<ul>\n<li>A single virtual memory address space can span up to 256 terrabytes of memory, making virtual memory much more plentiful than physical memory.</li>\n<li>Resolving virtual memory addresses into physical memory addresses is slow even when performed by dedicated hardware: modern CPUs spend something like 25% of their total execution time just doing this.</li>\n<li>Caching (the TLB) is used to mitigate this, and while its hit-rate is very high (96%+ in typical applications), it opens up timing-related side-channel attacks that have become well-known in recent years.</li>\n<li>Huge pages of 2 MB and 1 GB are another effort to improve performance, but are a mess, and difficult to work with in practice.</li>\n</ul>\n",
				"content_text": "I recently came by this fun story on getting an out-of-memory error on Linux when trying to _free_ memory: [Production postmortem: ENOMEM when trying to free memory](https://ayende.com/blog/199649-B/production-postmortem-enomem-when-trying-to-free-memory?Key=c9261116-c324-4280-a1e1-35da0d1fa882)\r\n> That error made absolutely no sense, as you can imagine. We are trying to release memory, not allocate it. Common sense says that you can’t really fail when you are freeing memory. After all, how can you run out of memory? I’m trying to give you some, damn it!\r\n\r\nThe linked blog post does a good job of explaining the problem briefly and clearly, so I'm just going to provide some further context on how this can indeed be a problem.\r\n\r\nModern computer architectures like x86-64 and even most (all?) the ARMs have a lot funkier relationship with memory than most people -- and even most software developers! -- tend to be aware of. (This is a good thing! You don't need to know how to sausage is made. Abstraction is an invaluable tool for managing complexity.)\r\n\r\nThe memory that a running application (any running application) sees and lives in (where it loads all of its data and where all of its allocations live) is actually not a direct representation of the main memory of the computer (the RAM sticks). It used to be, long ago, but we've moved away from that. Instead, what your process is interacting with is called _virtual memory_, or more specifically, a _virtual memory address-space_. Virtual memory is a layer of abstraction on top of _physical memory_, a decoupling useful because it grants additional performance, stability, and safety. How?\r\n\r\nA process's virtual memory address-space is constructed specifically for that one particular process, and reflects _only_ the parts of the physical memory that are used by it. Memory used by other processes is normally not visible here: it is simply not mapped (outside of special cases like shared memory created by [`shm_open()`](https://man7.org/linux/man-pages/man3/shm_open.3.html) and friends or debugging via [`ptrace()`](https://man7.org/linux/man-pages/man2/ptrace.2.html)). This means that, by default, no process can accidentally or maliciously access the memory of other processes and extract secrets from it or change the values in unexpected ways leading to erratic behaviour or crashes.\r\n\r\nThis layer of abstraction also enables other useful features that reduce overall memory usage at the expense of runtime performance:\r\n\r\n- Demand-paging: memory allocated but not yet accessed doesn't actually need to be available: if the application decided to allocate a gigantic 2 GB buffer but hasn't yet used more than 100 KB of it, then the rest doesn't have to be available\r\n- Swapping: rarely used regions of memory are written to disk, and the memory it was used for is made available for new allocations\r\n- Compression: rarely used regions of memory are compressed, and the space freed up is reclaimed for other purposes\r\n- De-duplication: if there are multiple identical copies of the sequence of bytes in memory, we don't actually need to store it multiple times (though caveats apply!)\r\n\r\nFor any physical memory to be accessible in a virtual memory address space, it has to be mapped in, typically by the operating system kernel. This is done by writing into a data structure called the _page table_, which is shared between the kernel and the CPU's memory management unit (MMU). A _page table entry_ typically represents the mapping of some physical memory region into a virtual memory address space: in this case, the entry will contain the physical memory address that it corresponds to. You may have multiple page table entries refer to the same or overlapping regions of physical memory: that is totally cool and allowed! (This has some very interesting uses e.g. in cybersecurity that I wrote [my Master's thesis on](https://github.com/shdnx/dangless-malloc).)\r\n\r\nA page table entry, beyond the physical memory address, also contains bits used for purposes. Some of these are used for protection, to indicate whether the region is readable, writable, or executable. This is enforced by the MMU: attempting to write to a virtual memory region whose page table entry does not have the writable bit set will fail (well, it will trigger a page fault, which can be handled -- more on this later). For example, after a running application's executable is loaded into memory at startup, the region is marked as non-writable (but readable and executable) to prevent buggy software from accidentally modifying its own code and also to limit the options of malware. Similarly, memory regions where the application's runtime data is stored (so the stack, the heap, but also the .data, .bss, and .rodata sections containing global variables) are marked as non-executable, as that is a very easy attack vector for malicious users.  (They can be made executable, otherwise things like Jit-in-Time compilers would not work, but you have to explicitly request it. e.g. on Linux by using `mmap()` with `PROT_EXEC`.)\r\n\r\nThe page table entry also contains a \"dirty\" bit. This is set the MMU whenever that particular memory region is used. The kernel can periodically clear this bit, and then check later if the bit is set: if not, then the corresponding memory region has not been used recently, and so may be candidate to be swapped out or compressed.\r\n\r\nWe need a mechanism though for detecting when e.g. a swapped-out piece of memory is accessed. Clearly, such an access cannot simply proceed as normal: the page table entry is marked as invalid, there is no physical memory backing it. The MMU will trigger a _page fault_ in this case, which is an interrupt that the kernel handles. The kernel will consult its own internal book-keeping of the process's memory and will find in this case that it has decided to swap the memory to disk: now, since the data is requested, the data must be loaded back from disk into main memory and the page table entry must be made valid again. Once this is done, the process resumes execution from the exact same place as it was left suspended when trying to access swapped memory, none the wiser to what happened in the background -- except perhaps that some operation ending up having taken much more time than usual.\r\n\r\nThis pattern is actually very common, and is used for all of the memory-use optimizations I've mentioned so far. For instance, in the case of memory de-duplication, identical memory regions may be referenced by multiple processes at the same time. So long as they all only read from it, life is good, but  when one of them wants to write to it, the kernel needs to intervene, as the write would make the memory region no longer contain what the other processes expect it to. This is achieved by marking the page table entries as non-writeable, such that attempting to write results in a page fault. On such page  fault, the kernel quietly duplicates the memory region (by allocating a new one and then copying into it) and updates the writing process's page table entry to point to the new address, restoring its writeability before returning control to the process.\r\n\r\nYou may have noticed that I was talking about individual bits of the page table entry. Indeed, these entries are extremely limited in size: typically just 64 bits (8 bytes), most of which is needed to store the referenced physical memory address. This is not always enough for more complicated features built on top of the virtual memory abstraction, so the kernel has additional book-keeping: in Linux, these are called _virtual memory areas_ or VMAs for short: one for each distinct memory region of each running process. For reasons of simplicity and performance, these VMAs are stored in a large pre-allocated array with a fixed capacity.\r\n\r\nThis takes us back to the blog post that motivated this write-up: freeing or de-allocating memory may require an additional VMA to be allocated in the case where you're not freeing an entire allocated memory region, but only a part of it. This is not possible to do via the commonly used `malloc()` / `free()` APIs or even the C++ `new` and `delete` equivalent operators, but it is possible to do via direct system calls using `mmap()` and `munmap()`. To illustrate:\r\n\r\n1. We allocate 1000 bytes of memory\r\n2. Linux creates a new VMA for us to record this (note: no actual memory has been allocated unless you used `MAP_POPULATE` as demand paging kicks in!)\r\n3. We now wish to free the middle 500 bytes\r\n4. Linux now has no choice but to split the original one VMA spanning 1000 bytes into two of 250 bytes each, with a 500 byte gap in the middle\r\n\r\nGranted, this is a bit contrived, and not even accurate as you cannot free 500 bytes: memory is split into pages of 4096 bytes (4 KB) each (by default, on x86-64). But you can imagine the same situation happening when e.g. different protection bits are applied to different parts of a huge memory region: some part of writeable, other parts are not. The VMA having to be split causes the memory deallocation operation to actually have to allocate memory: for the new VMA. This is how you can get an out-of-memory error.\r\n\r\nAs you can imagine, there are a lot more details to this topic. Some teasers:\r\n\r\n- A single virtual memory address space can span up to 256 terrabytes of memory, making virtual memory much more plentiful than physical memory.\r\n- Resolving virtual memory addresses into physical memory addresses is slow even when performed by dedicated hardware: modern CPUs spend something like 25% of their total execution time just doing this.\r\n- Caching (the TLB) is used to mitigate this, and while its hit-rate is very high (96%+ in typical applications), it opens up timing-related side-channel attacks that have become well-known in recent years.\r\n- Huge pages of 2 MB and 1 GB are another effort to improve performance, but are a mess, and difficult to work with in practice.\n",
				"date_published": "2023-07-15T03:10:14+02:00",
				"url": "https://blog.gaborkozar.me/2023/07/15/outofmemory-while-trying.html",
				"tags": ["software development"]
			},
			{
				"id": "http://shdnx.micro.blog/2023/07/15/brought-down-by.html",
				"title": "Brought down by the font",
				"content_html": "<p>Oh wow, now <em>this</em> is something: <a href=\"https://www.theverge.com/2017/7/12/15961354/pakistan-calibri-font-scandal-forged-documents\">A Microsoft font may have exposed corruption in Pakistan</a>:</p>\n<blockquote>\n<p>The Microsoft font Calibri is now a key piece of evidence in a corruption investigation surrounding Pakistan’s prime minister. Investigators noticed that documents handed over by the prime minister’s daughter, Maryam Nawaz Sharif, were typed up in the font Calibri. But the documents were dated from 2006 — and Calibri wasn’t widely available at that point, making a good case that they were forged.</p>\n</blockquote>\n<p>I love everything about this, but mostly just the fact that there are people know and care enough about fonts of all things to be able to point things like this out. This is true digital forensics. I almost feel sorry for Pakistani Prime Minister Nawaz Sharif! Not enough though to keep me from highlight this amazing snippet of peak journalism from Arstechnica&rsquo;s slightly more detailed article <a href=\"https://arstechnica.com/tech-policy/2017/07/not-for-the-first-time-microsofts-fonts-have-caught-out-forgers/\">Not for the first time, Microsoft’s fonts have caught out forgers</a>:</p>\n<blockquote>\n<p>Ultimately, the fallout of the corruption and cover-up is that Pakistan may soon, like Calibri itself, be sans-Sharif.</p>\n</blockquote>\n<p>The article goes on to note that this hasn&rsquo;t been the first time that fonts have been the demise of the mighty:</p>\n<blockquote>\n<p>Other Word features have caught out forgers, too. The &ldquo;Killian documents,&rdquo; which claimed President George W. Bush was declared unfit for service during his time with the Air National Guard, purported to have been produced on a typewriter in 1973. However, those documents used proportional fonts and curly quotes, making it spectacularly unlikely that they were authentic. Standard 1973 vintage typewriters didn&rsquo;t offer either proportional fonts or curly quotes, but 2004-vintage Microsoft Word did both.</p>\n</blockquote>\n<p>But yeah, apparently there are indeed people that both know and care a lot about fonts, such as <a href=\"https://www.youtube.com/watch?v=cJYm-de_UHE\">this guy who researched the market share of fonts used for memes</a>. Peak Friday evening material.</p>\n<p>This whole rabbit hole was enabled by the <a href=\"https://news.ycombinator.com/item?id=36719987\">Hacker News discussion</a> on Microsoft&rsquo;s new Aptos font, aimed to replace Calibre as the default, which I only even clicked on because I thought they were referring to <a href=\"https://calibre-ebook.com/\">Calibre the ebook management software</a> that I use.</p>\n",
				"content_text": "Oh wow, now *this* is something: [A Microsoft font may have exposed corruption in Pakistan](https://www.theverge.com/2017/7/12/15961354/pakistan-calibri-font-scandal-forged-documents):\n\n> The Microsoft font Calibri is now a key piece of evidence in a corruption investigation surrounding Pakistan’s prime minister. Investigators noticed that documents handed over by the prime minister’s daughter, Maryam Nawaz Sharif, were typed up in the font Calibri. But the documents were dated from 2006 — and Calibri wasn’t widely available at that point, making a good case that they were forged.\n\nI love everything about this, but mostly just the fact that there are people know and care enough about fonts of all things to be able to point things like this out. This is true digital forensics. I almost feel sorry for Pakistani Prime Minister Nawaz Sharif! Not enough though to keep me from highlight this amazing snippet of peak journalism from Arstechnica's slightly more detailed article [Not for the first time, Microsoft’s fonts have caught out forgers](https://arstechnica.com/tech-policy/2017/07/not-for-the-first-time-microsofts-fonts-have-caught-out-forgers/):\n> Ultimately, the fallout of the corruption and cover-up is that Pakistan may soon, like Calibri itself, be sans-Sharif.\n\nThe article goes on to note that this hasn't been the first time that fonts have been the demise of the mighty:\n> Other Word features have caught out forgers, too. The \"Killian documents,\" which claimed President George W. Bush was declared unfit for service during his time with the Air National Guard, purported to have been produced on a typewriter in 1973. However, those documents used proportional fonts and curly quotes, making it spectacularly unlikely that they were authentic. Standard 1973 vintage typewriters didn't offer either proportional fonts or curly quotes, but 2004-vintage Microsoft Word did both.\n\nBut yeah, apparently there are indeed people that both know and care a lot about fonts, such as [this guy who researched the market share of fonts used for memes](https://www.youtube.com/watch?v=cJYm-de_UHE). Peak Friday evening material.\n\nThis whole rabbit hole was enabled by the [Hacker News discussion](https://news.ycombinator.com/item?id=36719987) on Microsoft's new Aptos font, aimed to replace Calibre as the default, which I only even clicked on because I thought they were referring to [Calibre the ebook management software](https://calibre-ebook.com/) that I use.\n",
				"date_published": "2023-07-15T01:11:22+02:00",
				"url": "https://blog.gaborkozar.me/2023/07/15/brought-down-by.html",
				"tags": ["technology"]
			},
			{
				"id": "http://shdnx.micro.blog/2023/07/12/writing-a-popular.html",
				"title": "Writing a popular blog must be dreadful",
				"content_html": "<p>In <a href=\"https://astralcodexten.substack.com/p/why-do-i-suck\">Why do I suck</a>, Scott Alexander is analyzing why his earlier articles (from 2013 - 2016) were much more popular than his recent ones.</p>\n<p>I would like to highlight his insight into the perception difference between a small blog and a big one:</p>\n<blockquote>\n<p>If you have a small blog, and you have a cool thought or insight, you can post your cool thought or insight. People will say “interesting, I never thought of that before” and have vaguely positive feelings about you. If you have a big blog, people will get angry. They’ll feel it’s insulting for you to have opinions about a field when there are hundreds of experts who have written thousands of books about the field which you haven’t read. Unless you cite a dozen sources, it will be “armchair speculation” and you’ll be “speaking over real academics”. If anyone has ever had the same thought before, you’re plagiarizing them, or “reinventing the wheel”, or acting like a “guru”, or claiming that all knowledge springs Athena-like from your head with no prior influences.</p>\n<p>I try really hard to block or ignore these people when I spot them, but they do a little bit of psychic damage each time.</p>\n</blockquote>\n<p>I wonder how much of that is simply bigger audience = worse audience, given <a href=\"https://en.wikipedia.org/wiki/Regression_toward_the_mean\">regression to the mean</a>. Basically: when your blog has 100 readers, it is not difficult for this 100 to be &ldquo;reasonable people&rdquo; (from you, the blog author&rsquo;s, perspective), but if you have 10 000, then it is much harder: as the size of a group grows, the more it tends to resemble the population at large. The population as a whole contains a whole lot of people who suck! (This seems universally true, regardless of what group you identify with.)</p>\n<p>Another perspective on the same idea: out of 10 000 people, you&rsquo;re much more likely to annoy / step on the toes of somebody by something you write than out of 100 people. 10 000 people will also likely contain some trolls and griefers, who just tend to make things worse.</p>\n<p>The other possible explanation is authority. A blog with few readers has little to no authority on any subject, and therefore is largely safe from the kind of scrutiny that having authority (even informal!) invites. So you can get away just expressing your opinions in a way that makes sense to you. Doing so when you have a large audience is risky, expectations are higher, and the whole thing becomes a lot more high-stakes.</p>\n<p>Taking this further, what does this mean for official authorities like the CDC or the FED? Obviously that&rsquo;s kind of as high-stakes as it gets, but beyond that, they are very constrained in what they can actually say if they want people to actually take them seriously. They can&rsquo;t just say things that make sense to them! It needs to be as unambiguous as possible, supported by research and data.</p>\n<hr>\n<p>As an aside, I find it interesting that one of his plausible explanations is just that media overall is less bad today than it used to be. Not often do you see this proposed!</p>\n<blockquote>\n<p>Nowadays I think there are many good science bloggers, and the media has gotten embarrassed enough times that it will sometimes run a take by someone who knows what they’re talking about before publishing it.</p>\n<p>In the same way, I see fewer people outright denying the existence of genetics, totally failing to understand AI risk, or utterly bungling basic concepts in risk and probability.</p>\n</blockquote>\n",
				"content_text": "In [Why do I suck](https://astralcodexten.substack.com/p/why-do-i-suck), Scott Alexander is analyzing why his earlier articles (from 2013 - 2016) were much more popular than his recent ones.\r\n\r\nI would like to highlight his insight into the perception difference between a small blog and a big one:\r\n> If you have a small blog, and you have a cool thought or insight, you can post your cool thought or insight. People will say “interesting, I never thought of that before” and have vaguely positive feelings about you. If you have a big blog, people will get angry. They’ll feel it’s insulting for you to have opinions about a field when there are hundreds of experts who have written thousands of books about the field which you haven’t read. Unless you cite a dozen sources, it will be “armchair speculation” and you’ll be “speaking over real academics”. If anyone has ever had the same thought before, you’re plagiarizing them, or “reinventing the wheel”, or acting like a “guru”, or claiming that all knowledge springs Athena-like from your head with no prior influences.\r\n> \r\n> I try really hard to block or ignore these people when I spot them, but they do a little bit of psychic damage each time.\r\n\r\nI wonder how much of that is simply bigger audience = worse audience, given [regression to the mean](https://en.wikipedia.org/wiki/Regression_toward_the_mean). Basically: when your blog has 100 readers, it is not difficult for this 100 to be \"reasonable people\" (from you, the blog author's, perspective), but if you have 10 000, then it is much harder: as the size of a group grows, the more it tends to resemble the population at large. The population as a whole contains a whole lot of people who suck! (This seems universally true, regardless of what group you identify with.)\r\n\r\nAnother perspective on the same idea: out of 10 000 people, you're much more likely to annoy / step on the toes of somebody by something you write than out of 100 people. 10 000 people will also likely contain some trolls and griefers, who just tend to make things worse.\r\n\r\nThe other possible explanation is authority. A blog with few readers has little to no authority on any subject, and therefore is largely safe from the kind of scrutiny that having authority (even informal!) invites. So you can get away just expressing your opinions in a way that makes sense to you. Doing so when you have a large audience is risky, expectations are higher, and the whole thing becomes a lot more high-stakes.\r\n\r\nTaking this further, what does this mean for official authorities like the CDC or the FED? Obviously that's kind of as high-stakes as it gets, but beyond that, they are very constrained in what they can actually say if they want people to actually take them seriously. They can't just say things that make sense to them! It needs to be as unambiguous as possible, supported by research and data.\r\n\r\n----\r\n\r\nAs an aside, I find it interesting that one of his plausible explanations is just that media overall is less bad today than it used to be. Not often do you see this proposed!\r\n> Nowadays I think there are many good science bloggers, and the media has gotten embarrassed enough times that it will sometimes run a take by someone who knows what they’re talking about before publishing it.\r\n> \r\n> In the same way, I see fewer people outright denying the existence of genetics, totally failing to understand AI risk, or utterly bungling basic concepts in risk and probability.\n",
				"date_published": "2023-07-12T01:38:49+02:00",
				"url": "https://blog.gaborkozar.me/2023/07/12/writing-a-popular.html"
			},
			{
				"id": "http://shdnx.micro.blog/2023/07/08/regulation-unexpected-consequences.html",
				"title": "Regulation, unexpected consequences of (Sesame edition)",
				"content_html": "<p>Matt Levine writes the amazing <a href=\"https://www.bloomberg.com/opinion/authors/ARbTQlRLRjE/matthew-s-levine\">Money Stuff</a> newsletter for Bloomberg. I&rsquo;ve been a reader of his for a few years now, and I&rsquo;m a huge fan of his writing. He recently wrote about the <a href=\"https://www.bloomberg.com/opinion/articles/2023-06-21/big-firms-want-normal-crypto-markets\">new US legislation on sesame seeds</a> (search for the title &ldquo;Sesame&rdquo;) that I found hilarious:</p>\n<blockquote>\n<p>Congress passed legislation intended to make life better for people allergic to sesame seeds. Instead, it made things worse.\nThe bill, passed with overwhelming bipartisan support and signed into law by President Biden in 2021, requires manufacturers to label sesame on their products starting this year.</p>\n<p>In response, some companies began adding sesame to products that hadn’t included it in the past—saying it was safer to add sesame and label it, rather than certify they had eliminated all traces of it.</p>\n</blockquote>\n<p>Why would they do that? Clearly, if anything, that&rsquo;s the opposite of what the new regulation was intended for. Well:</p>\n<blockquote>\n<p>The issue is that it is hard to eliminate trace amounts of sesame, and the law now requires food manufacturers to label sesame as an allergen. Not putting sesame on the label effectively constitutes a promise that there is no sesame in the product, and if there is a little bit then you get in trouble: [&hellip;]</p>\n<p>But if you say that the product definitely contains sesame, then you are immunized from trouble. So you just chuck some sesame into everything, change the labels, and you’re fine. It is easier to make sure that there is sesame than that there isn’t, so that’s what companies do.</p>\n</blockquote>\n<p>Unintended consequences! It <em>makes sense</em> that companies do this, given their incentives. A friend of mine put it as &ldquo;regulators just do not think like hackers&rdquo;, which is not how I&rsquo;d put it, but I do see his point: regulators should have known better than to do this. Don&rsquo;t they consult with experts and people in the industry? Someone would have definitely pointed this out to them.</p>\n",
				"content_text": "Matt Levine writes the amazing [Money Stuff](https://www.bloomberg.com/opinion/authors/ARbTQlRLRjE/matthew-s-levine) newsletter for Bloomberg. I've been a reader of his for a few years now, and I'm a huge fan of his writing. He recently wrote about the [new US legislation on sesame seeds](https://www.bloomberg.com/opinion/articles/2023-06-21/big-firms-want-normal-crypto-markets) (search for the title \"Sesame\") that I found hilarious:\r\n\r\n> Congress passed legislation intended to make life better for people allergic to sesame seeds. Instead, it made things worse.\r\n> The bill, passed with overwhelming bipartisan support and signed into law by President Biden in 2021, requires manufacturers to label sesame on their products starting this year.\r\n> \r\n> In response, some companies began adding sesame to products that hadn’t included it in the past—saying it was safer to add sesame and label it, rather than certify they had eliminated all traces of it.\r\n\r\nWhy would they do that? Clearly, if anything, that's the opposite of what the new regulation was intended for. Well:\r\n\r\n> The issue is that it is hard to eliminate trace amounts of sesame, and the law now requires food manufacturers to label sesame as an allergen. Not putting sesame on the label effectively constitutes a promise that there is no sesame in the product, and if there is a little bit then you get in trouble: [...]\r\n> \r\n> But if you say that the product definitely contains sesame, then you are immunized from trouble. So you just chuck some sesame into everything, change the labels, and you’re fine. It is easier to make sure that there is sesame than that there isn’t, so that’s what companies do.\r\n\r\nUnintended consequences! It _makes sense_ that companies do this, given their incentives. A friend of mine put it as \"regulators just do not think like hackers\", which is not how I'd put it, but I do see his point: regulators should have known better than to do this. Don't they consult with experts and people in the industry? Someone would have definitely pointed this out to them.\n",
				"date_published": "2023-07-08T23:43:54+02:00",
				"url": "https://blog.gaborkozar.me/2023/07/08/regulation-unexpected-consequences.html"
			},
			{
				"id": "http://shdnx.micro.blog/2023/07/06/the-twitterkiller-metas.html",
				"title": "The Twitter-killer? Meta's new Threads app",
				"content_html": "<p>Facebook (err, sorry, Meta) is launching their Twitter competitor today in the US in the form of a new stand-alone app called <a href=\"https://apps.apple.com/us/app/threads-an-instagram-app/id6446901002\">Threads</a>.</p>\n<p>The Verge has a good summary on what is known: <a href=\"https://www.theverge.com/2023/7/5/23784480/threads-instagram-meta-news-twitter-competitor\">Instagram’s Threads: all the updates on the new Twitter competitor</a>. I can also recommend the <a href=\"https://news.ycombinator.com/item?id=36580192\">Hacker News thread</a>; it has received quite a bit of attention and drew a lot of discussion.</p>\n<blockquote>\n<p>As Twitter continues to flail about under Elon Musk, all eyes are on Instagram Threads as a potential replacement.</p>\n</blockquote>\n<p>Twitter&rsquo;s story with getting bought by Elon Musk is truly wild, and semi-seriously could be turned into a movie. Matt Levine wrote a lot about it in his excellent Money Stuff, and it was all great fun, truly peak 21st century amusement. Since the acquisition, Twitter has arguably received more attention than before, but also a lot more criticism, and is <a href=\"https://www.dexerto.com/tech/twitter-users-claim-elon-musks-recent-changes-may-be-self-ddosing-the-platform-2196413/\">clearly struggling</a>, <a href=\"https://daringfireball.net/linked/2023/07/03/everything-continues-to-be-going-just-great-at-twitter\">dear lord</a>, with even <a href=\"https://mashable.com/article/twitter-api-elon-musk-developer-issues-apps\">high-paying customers being ignored</a>.</p>\n<p>Elon Musk himself has stated multiple times that bankruptcy in the near future was possible. It remains to be seen whether these are the kind of temporary issues that can be expected from a fairly dramatic shift in leadership and strategy, or perhaps the beginning of the end of Twitter&rsquo;s prevalence.\nEither way, this is excellent timing from Meta, and I expect they have a good chance of capitalizing on Twitter&rsquo;s plight.</p>\n<blockquote>\n<p>From what we know so far, Threads is “Instagram’s text-based conversation app” where “communities come together to discuss everything from the topics you care about today to what’ll be trending tomorrow.” The app is closely tied to Instagram, meaning you’ll get to use the same username across both apps, as well as quickly follow all of the accounts you’ve been following on Instagram.</p>\n</blockquote>\n<p>Sounds a lot like Twitter, i.e. a more social version of micro-blogging. Reportedly it will even have two-way <a href=\"https://joinmastodon.org/\">Mastodon</a> integration, which is interesting and again a good move: Mastodon gained some popularity following Twitter&rsquo;s, uh, adventures, and by embracing it, Threads can attempt to woo Twitter refugees more effectively than by <em>not</em> integrating&hellip; not to mention, it&rsquo;s a greater blow to Twitter.</p>\n<blockquote>\n<p>The Twitter alternative from Meta appears set to launch on July 6th, but the Irish Independent reports that Ireland’s Data Protection Commission has been in contact with the company about the new product and confirmed the launch won’t extend to the EU “at this point.”</p>\n</blockquote>\n<p>GDPR strikes again! I will be curious to see what happens here; no doubt there&rsquo;s an element of power play here on the part of Meta. GDPR and other privacy legislation in the EU are clearly anti-Meta; Meta is probably evaluating whether it makes sense to even bother with it.</p>\n<hr>\n<p>An interesting perspective to take is that Threads appears to be very much like Facebook&rsquo;s own Wall, where people can write posts, upload photos, and engage with people in the comments. Facebook&rsquo;s own shift towards providing something more like a news feed has reduced the Wall&rsquo;s relevance a lot, but the Threads can potentially be its reincarnation in a purer form.</p>\n<p>Threads is cleverly branded under Instagram rather than Facebook or Meta to leverage its better reputation. Meta knows that as far as associations go, people (at least in much of the US and Europe) tend to like and trust Instagram, but tend to at least distrust Facebook or Meta. Many, many people still aren&rsquo;t really aware that Instagram, and even WhatsApp are owned and operated by Meta now! They&rsquo;d very much like to keep it this way.</p>\n<p>Branding- and image-wise, Meta is in an interesting situation. On the one hand, both in the United States and much of Europe, Facebook is generally a disliked and mistrusted brand, following lots and lots of bad publicity from, well, being Facebook and doing Facebook things. On the other hand, they still have a metric ton of daily active users, passing <a href=\"https://www.statista.com/statistics/346167/facebook-global-dau/\">2 billion recently</a>, so clearly they are, uh, successful. Sadly.</p>\n",
				"content_text": "Facebook (err, sorry, Meta) is launching their Twitter competitor today in the US in the form of a new stand-alone app called [Threads](https://apps.apple.com/us/app/threads-an-instagram-app/id6446901002).\n\nThe Verge has a good summary on what is known: [Instagram’s Threads: all the updates on the new Twitter competitor](https://www.theverge.com/2023/7/5/23784480/threads-instagram-meta-news-twitter-competitor). I can also recommend the [Hacker News thread](https://news.ycombinator.com/item?id=36580192); it has received quite a bit of attention and drew a lot of discussion.\n\n> As Twitter continues to flail about under Elon Musk, all eyes are on Instagram Threads as a potential replacement.\n\nTwitter's story with getting bought by Elon Musk is truly wild, and semi-seriously could be turned into a movie. Matt Levine wrote a lot about it in his excellent Money Stuff, and it was all great fun, truly peak 21st century amusement. Since the acquisition, Twitter has arguably received more attention than before, but also a lot more criticism, and is [clearly struggling](https://www.dexerto.com/tech/twitter-users-claim-elon-musks-recent-changes-may-be-self-ddosing-the-platform-2196413/), [dear lord](https://daringfireball.net/linked/2023/07/03/everything-continues-to-be-going-just-great-at-twitter), with even [high-paying customers being ignored](https://mashable.com/article/twitter-api-elon-musk-developer-issues-apps).\n\nElon Musk himself has stated multiple times that bankruptcy in the near future was possible. It remains to be seen whether these are the kind of temporary issues that can be expected from a fairly dramatic shift in leadership and strategy, or perhaps the beginning of the end of Twitter's prevalence.\nEither way, this is excellent timing from Meta, and I expect they have a good chance of capitalizing on Twitter's plight.\n\n> From what we know so far, Threads is “Instagram’s text-based conversation app” where “communities come together to discuss everything from the topics you care about today to what’ll be trending tomorrow.” The app is closely tied to Instagram, meaning you’ll get to use the same username across both apps, as well as quickly follow all of the accounts you’ve been following on Instagram. \n\nSounds a lot like Twitter, i.e. a more social version of micro-blogging. Reportedly it will even have two-way [Mastodon](https://joinmastodon.org/) integration, which is interesting and again a good move: Mastodon gained some popularity following Twitter's, uh, adventures, and by embracing it, Threads can attempt to woo Twitter refugees more effectively than by *not* integrating... not to mention, it's a greater blow to Twitter.\n\n> The Twitter alternative from Meta appears set to launch on July 6th, but the Irish Independent reports that Ireland’s Data Protection Commission has been in contact with the company about the new product and confirmed the launch won’t extend to the EU “at this point.”\n\nGDPR strikes again! I will be curious to see what happens here; no doubt there's an element of power play here on the part of Meta. GDPR and other privacy legislation in the EU are clearly anti-Meta; Meta is probably evaluating whether it makes sense to even bother with it.\n\n-----\n\nAn interesting perspective to take is that Threads appears to be very much like Facebook's own Wall, where people can write posts, upload photos, and engage with people in the comments. Facebook's own shift towards providing something more like a news feed has reduced the Wall's relevance a lot, but the Threads can potentially be its reincarnation in a purer form.\n\nThreads is cleverly branded under Instagram rather than Facebook or Meta to leverage its better reputation. Meta knows that as far as associations go, people (at least in much of the US and Europe) tend to like and trust Instagram, but tend to at least distrust Facebook or Meta. Many, many people still aren't really aware that Instagram, and even WhatsApp are owned and operated by Meta now! They'd very much like to keep it this way.\n\nBranding- and image-wise, Meta is in an interesting situation. On the one hand, both in the United States and much of Europe, Facebook is generally a disliked and mistrusted brand, following lots and lots of bad publicity from, well, being Facebook and doing Facebook things. On the other hand, they still have a metric ton of daily active users, passing [2 billion recently](https://www.statista.com/statistics/346167/facebook-global-dau/), so clearly they are, uh, successful. Sadly.\n",
				"date_published": "2023-07-06T00:29:43+02:00",
				"url": "https://blog.gaborkozar.me/2023/07/06/the-twitterkiller-metas.html",
				"tags": ["technology"]
			},
			{
				"id": "http://shdnx.micro.blog/2023/07/04/quantum-immortality-explored.html",
				"title": "Quantum immortality",
				"content_html": "<p>Quantum immortality is a thought experiment that runs roughly like follows:</p>\n<ol>\n<li>If the many-worlds interpretation of quantum mechanics is correct, each &ldquo;choice&rdquo; (however this may be defined) creates a branching point: there will be a universe that explores each possibility. Simply put, if at an intersection you can choose to go left or right, in one universe you&rsquo;ll always go left, and in another you&rsquo;ll always go right, and the history of each universe will then evolve independently, and continue branching along each subsequent choice.</li>\n<li>Which one of these many many universes will <em>you</em> (the awareness reading this text) experience? You are clearly in one of them: your awareness does not span universes. (At least, I would expect so. My apologies if it does! Please drop me an e-mail, I&rsquo;ll buy you a coffee.)</li>\n<li>A person, pretty much by definition, is incapable of experiencing their own death. So you are clearly experiencing a universe in which you are not dead. (Again, my honest apologies if you are! Please drop me an e-mail, let&rsquo;s chat.)</li>\n<li>What if this rule is universal? What if your awareness will always continue along a path of these possible universes where you remain alive (or perhaps just aware), however unlikely that may be?</li>\n</ol>\n<p><strong>Disclaimer</strong>: <em>This is purely a thought experiment. Do not take this seriously. As far as anyone can tell, you only have one life: do not throw it away.</em></p>\n<p>This idea has some interesting consequences! The following is a short story by Robert Charles Wilson, originally published in 1998 (!), that explores this:</p>\n<h3 id=\"divided-by-infinityhttpswwwtorcom20100805divided-by-infinity\"><a href=\"https://www.tor.com/2010/08/05/divided-by-infinity/\">Divided by Infinity</a></h3>\n<hr>\n<p>As I said, interesting idea! It would imply that you get away with any crazy shit! For starters:</p>\n<ol>\n<li>Buy a lottery ticket.</li>\n<li>Set up some mechanism that will kill you immediately and without warning, should it turn out that you have <strong>not</strong> won the lottery.</li>\n<li>Profit??</li>\n</ol>\n<p>Obviously this is not fool-proof, and, err, certainly not lifestyle advice! This would just be testing the likelihood of whatever mechanism you have set up failing against the likelihood of you winning the lottery. Examples of how this may come to be include but are not limited to:</p>\n<ul>\n<li>If you hire somebody to kill you, they will have an accident or something else that prevents them from completing their task.</li>\n<li>If you set up some kind of machine or contraption, it will fail. The more fail-safe you make it, it will start failing in increasingly less plausible ways.</li>\n<li>The lottery gets cancelled.</li>\n<li>You win the lottery, but after the fact, your ticket turns out to be invalid or counterfeit.</li>\n</ul>\n<p>Another interesting consequence of this thought experiment is that it only confers &ldquo;immortality&rdquo; to <em>your own subjective awareness</em> or viewpoint. It does not protect others! So if you watch somebody else try e.g. the above, the result will most likely be the predictable one: they die. In <em>your</em> perspective that is, or rather, in the universe that you are experiencing. In <em>their</em> subjective perspective, they will survive; it will just not be a universe that you can ever experience or interact with.</p>\n<p>Finally, we have been talking about <em>immortality</em>, but the premise does not actually promise that. It only promises a <strong>continuity of awareness</strong>. This does not protect against you suffering a horrible accident that will leave you alive and aware, but miserable! The possibilities start with the run-of-the-mill horribleness that comes from inhabiting a physical body (e.g. going blind or becoming totally paralyzed), but actually go much further: you could find yourself at the mercy of aliens experimenting on you, or your consciousness (and awareness) being uploaded into a computer and then being subjected to&hellip; whatever.</p>\n<p>I will leave this here before it gets any darker. :)</p>\n<p>To end this post on a lighter note, here is an only tangentially related but fun short story video about a guy using a One-minute Time Machine to try to pick up a woman. Enjoy:</p>\n<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style>\n<div class='embed-container'><iframe src='https://www.youtube.com/embed/CXhnPLMIET0' frameborder='0' allowfullscreen></iframe></div>\n<p>(Thank you Melvin for the recommendation!)</p>\n",
				"content_text": "Quantum immortality is a thought experiment that runs roughly like follows:\n\n1. If the many-worlds interpretation of quantum mechanics is correct, each \"choice\" (however this may be defined) creates a branching point: there will be a universe that explores each possibility. Simply put, if at an intersection you can choose to go left or right, in one universe you'll always go left, and in another you'll always go right, and the history of each universe will then evolve independently, and continue branching along each subsequent choice.\n2. Which one of these many many universes will _you_ (the awareness reading this text) experience? You are clearly in one of them: your awareness does not span universes. (At least, I would expect so. My apologies if it does! Please drop me an e-mail, I'll buy you a coffee.)\n3. A person, pretty much by definition, is incapable of experiencing their own death. So you are clearly experiencing a universe in which you are not dead. (Again, my honest apologies if you are! Please drop me an e-mail, let's chat.)\n4. What if this rule is universal? What if your awareness will always continue along a path of these possible universes where you remain alive (or perhaps just aware), however unlikely that may be?\n\n**Disclaimer**: *This is purely a thought experiment. Do not take this seriously. As far as anyone can tell, you only have one life: do not throw it away.*\n\nThis idea has some interesting consequences! The following is a short story by Robert Charles Wilson, originally published in 1998 (!), that explores this:\n### [Divided by Infinity](https://www.tor.com/2010/08/05/divided-by-infinity/)\n\n---------\n\nAs I said, interesting idea! It would imply that you get away with any crazy shit! For starters:\n\n1. Buy a lottery ticket.\n2. Set up some mechanism that will kill you immediately and without warning, should it turn out that you have **not** won the lottery.\n3. Profit??\n\nObviously this is not fool-proof, and, err, certainly not lifestyle advice! This would just be testing the likelihood of whatever mechanism you have set up failing against the likelihood of you winning the lottery. Examples of how this may come to be include but are not limited to:\n\n- If you hire somebody to kill you, they will have an accident or something else that prevents them from completing their task.\n- If you set up some kind of machine or contraption, it will fail. The more fail-safe you make it, it will start failing in increasingly less plausible ways.\n- The lottery gets cancelled.\n- You win the lottery, but after the fact, your ticket turns out to be invalid or counterfeit.\n\nAnother interesting consequence of this thought experiment is that it only confers \"immortality\" to _your own subjective awareness_ or viewpoint. It does not protect others! So if you watch somebody else try e.g. the above, the result will most likely be the predictable one: they die. In _your_ perspective that is, or rather, in the universe that you are experiencing. In _their_ subjective perspective, they will survive; it will just not be a universe that you can ever experience or interact with.\n\nFinally, we have been talking about _immortality_, but the premise does not actually promise that. It only promises a **continuity of awareness**. This does not protect against you suffering a horrible accident that will leave you alive and aware, but miserable! The possibilities start with the run-of-the-mill horribleness that comes from inhabiting a physical body (e.g. going blind or becoming totally paralyzed), but actually go much further: you could find yourself at the mercy of aliens experimenting on you, or your consciousness (and awareness) being uploaded into a computer and then being subjected to... whatever.\n\nI will leave this here before it gets any darker. :)\n\nTo end this post on a lighter note, here is an only tangentially related but fun short story video about a guy using a One-minute Time Machine to try to pick up a woman. Enjoy:\n\n{{<youtube CXhnPLMIET0>}}\n\n(Thank you Melvin for the recommendation!)\n",
				"date_published": "2023-07-04T19:49:34+02:00",
				"url": "https://blog.gaborkozar.me/2023/07/04/quantum-immortality-explored.html",
				"tags": ["thoughtexperiments and ideas"]
			},
			{
				"id": "http://shdnx.micro.blog/2023/07/01/light-and-fun.html",
				"title": "Light and fun fiction: Idol Words",
				"content_html": "<p>At this point my blog has been alive for a few days now, and so it&rsquo;s high time I mentioned Scott Alexander, and his blog(s): the Star Slate Codex and Astral Codex Ten. He writes about complex topics in a refreshingly sober, straight-forward and illuminating manner. His articles will most definitely make a regular appearance here.</p>\n<p>To start with, I would recommend a light and short piece of fiction he wrote: Idol Words. It&rsquo;s more a series of short scenes rather than a short story.\nIt semi-seriously explores the idea of three omniscient idols, one of which always tells the truth, one of which always lies, and one of which answers randomly, with each &ldquo;scene&rdquo; featuring another person coming along to ask them a question. What kind of people would ask what kind of questions? The themes are perhaps predictable, but no less interesting or satisfying to read.</p>\n<p>Enjoy:</p>\n<h1 id=\"idol-wordshttpsastralcodextensubstackcompidol-words\"><a href=\"https://astralcodexten.substack.com/p/idol-words\">Idol Words</a></h1>\n<blockquote>\n<p>It was another boring day as the keeper of the three omniscient idols, one of which always tells the truth, one of which always lies, and one of which answers randomly.</p>\n</blockquote>\n",
				"content_text": "At this point my blog has been alive for a few days now, and so it's high time I mentioned Scott Alexander, and his blog(s): the Star Slate Codex and Astral Codex Ten. He writes about complex topics in a refreshingly sober, straight-forward and illuminating manner. His articles will most definitely make a regular appearance here.\n\nTo start with, I would recommend a light and short piece of fiction he wrote: Idol Words. It's more a series of short scenes rather than a short story.\nIt semi-seriously explores the idea of three omniscient idols, one of which always tells the truth, one of which always lies, and one of which answers randomly, with each \"scene\" featuring another person coming along to ask them a question. What kind of people would ask what kind of questions? The themes are perhaps predictable, but no less interesting or satisfying to read.\n\nEnjoy:\n\n# [Idol Words](https://astralcodexten.substack.com/p/idol-words)\n> It was another boring day as the keeper of the three omniscient idols, one of which always tells the truth, one of which always lies, and one of which answers randomly.\n",
				"date_published": "2023-07-01T18:18:28+02:00",
				"url": "https://blog.gaborkozar.me/2023/07/01/light-and-fun.html",
				"tags": ["thoughtexperiments and ideas"]
			},
			{
				"id": "http://shdnx.micro.blog/2023/06/30/im-very-excited.html",
				"title": "The Three Body Problem",
				"content_html": "<p>I&rsquo;m very excited for the upcoming The Three Body Problem series!\nI&rsquo;ve read and thoroughly enjoyed <a href=\"https://www.goodreads.com/book/show/20518872-the-three-body-problem\">the book trilogy</a>, and it looks like they are sticking decently close to the source material. This must be a challenging story to put on screen!</p>\n<p>The book&rsquo;s cover text:</p>\n<blockquote>\n<p>Set against the backdrop of China&rsquo;s Cultural Revolution, a secret military project sends signals into space to establish contact with aliens. An alien civilization on the brink of destruction captures the signal and plans to invade Earth. Meanwhile, on Earth, different camps start forming, planning to either welcome the superior beings and help them take over a world seen as corrupt, or to fight against the invasion.</p>\n</blockquote>\n<p>You can watch the teaser trailer for the series on YouTube:\n<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style>\n<div class='embed-container'><iframe src='https://www.youtube.com/embed/5lj99Uz1d50' frameborder='0' allowfullscreen></iframe></div></p>\n<p>The books form a trilogy, so the series will have plenty of material to work with!\nMy favorite book was the second, titled <a href=\"https://www.goodreads.com/book/show/23168817-the-dark-forest\">The Dark Forest</a>, with a host of exciting new ideas, including a to me previously unknown theoretical explanation for the <a href=\"https://en.wikipedia.org/wiki/Fermi_paradox\">Fermi Paradox</a>.</p>\n<p>As an aside, this short video gives a brief explanation on the title-giving N-body Problem: that is, we can model the behaviour of a gravitational system with 2 objects, but we are incapable of doing so for 3 or more objects. That&rsquo;s kind of a problem, especially if you happen to live in a solar system with, let&rsquo;s say, 3 stars&hellip; :)\n<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style>\n<div class='embed-container'><iframe src='https://www.youtube.com/embed/D89ngRr4uZg' frameborder='0' allowfullscreen></iframe></div></p>\n",
				"content_text": "I'm very excited for the upcoming The Three Body Problem series!\nI've read and thoroughly enjoyed [the book trilogy](https://www.goodreads.com/book/show/20518872-the-three-body-problem), and it looks like they are sticking decently close to the source material. This must be a challenging story to put on screen!\n\nThe book's cover text:\n> Set against the backdrop of China's Cultural Revolution, a secret military project sends signals into space to establish contact with aliens. An alien civilization on the brink of destruction captures the signal and plans to invade Earth. Meanwhile, on Earth, different camps start forming, planning to either welcome the superior beings and help them take over a world seen as corrupt, or to fight against the invasion.\n\nYou can watch the teaser trailer for the series on YouTube:\n{{<youtube 5lj99Uz1d50>}}\n\nThe books form a trilogy, so the series will have plenty of material to work with!\nMy favorite book was the second, titled [The Dark Forest](https://www.goodreads.com/book/show/23168817-the-dark-forest), with a host of exciting new ideas, including a to me previously unknown theoretical explanation for the [Fermi Paradox](https://en.wikipedia.org/wiki/Fermi_paradox).\n\nAs an aside, this short video gives a brief explanation on the title-giving N-body Problem: that is, we can model the behaviour of a gravitational system with 2 objects, but we are incapable of doing so for 3 or more objects. That's kind of a problem, especially if you happen to live in a solar system with, let's say, 3 stars... :)\n{{<youtube D89ngRr4uZg>}}\n",
				"date_published": "2023-06-30T00:44:10+02:00",
				"url": "https://blog.gaborkozar.me/2023/06/30/im-very-excited.html",
				"tags": ["movies series and books"]
			},
			{
				"id": "http://shdnx.micro.blog/2023/06/30/inside-the-ai.html",
				"title": "Inside the AI factory: the human element of AIs",
				"content_html": "<p>A fascinating deep-dive from New York Magazine and The Verge into how AI models &ndash; including ChatGPT, Bard, and other LLMs (Large Language Models) &ndash; are trained, and the industry that provides the data, control, and feedback:</p>\n<h2 id=\"inside-the-ai-factoryhttpsnymagcomintelligencerarticleai-artificial-intelligence-humans-technology-business-factoryhtml\"><a href=\"https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html\">Inside the AI factory</a></h2>\n<blockquote>\n<p>[&hellip;] ChatGPT seems so human because it was trained by an AI that was mimicking humans who were rating an AI that was mimicking humans who were pretending to be a better version of an AI that was trained on human writing.</p>\n<p>This circuitous technique is called “reinforcement learning from human feedback,” or RLHF, and it’s so effective that it’s worth pausing to fully register what it doesn’t do. When annotators teach a model to be accurate, for example, the model isn’t learning to check answers against logic or external sources or about what accuracy as a concept even is. The model is still a text-prediction machine mimicking patterns in human writing, but now its training corpus has been supplemented with bespoke examples, and the model has been weighted to favor them. Maybe this results in the model extracting patterns from the part of its linguistic map labeled as accurate and producing text that happens to align with the truth, but it can also result in it mimicking the confident style and expert jargon of the accurate text while writing things that are totally wrong. There is no guarantee that the text the labelers marked as accurate is in fact accurate, and when it is, there is no guarantee that the model learns the right patterns from it.</p>\n</blockquote>\n<p>Makes sense, and it&rsquo;s so very important to recognize this! We, humans, like to anthropomorphize things, and doubly so for LLMs since they can come across so&hellip; genuinely human.</p>\n<p>Generating training data for AIs though appears&hellip; distinctly not-so-fun, mainly because it is so alien. Indeed, you are training an <em>excessively dumb</em> machine:</p>\n<blockquote>\n<p>It is in part a product of the way machine-learning systems learn. Where a human would get the concept of “shirt” with a few examples, machine-learning programs need thousands, and they need to be categorized with perfect consistency yet varied enough (polo shirts, shirts being worn outdoors, shirts hanging on a rack) that the very literal system can handle the diversity of the real world.\n[&hellip;]\nInstruction writers must come up with rules that will get humans to categorize the world with perfect consistency. To do so, they often create categories no human would use. A human asked to tag all the shirts in a photo probably wouldn’t tag the reflection of a shirt in a mirror because they would know it is a reflection and not real. But to the AI, which has no understanding of the world, it’s all just pixels and the two are perfectly identical. Fed a dataset with some shirts labeled and other (reflected) shirts unlabeled, the model won’t work. So the engineer goes back to the vendor with an update: DO label reflections of shirts. Soon, you have a 43-page guide descending into red all-caps.</p>\n</blockquote>\n<p>I fear though that before this era is over, most of us will have a &ldquo;job&rdquo; like this one, if indeed any at all.</p>\n",
				"content_text": "A fascinating deep-dive from New York Magazine and The Verge into how AI models -- including ChatGPT, Bard, and other LLMs (Large Language Models) -- are trained, and the industry that provides the data, control, and feedback:\n\n## [Inside the AI factory](https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html)\n> [...] ChatGPT seems so human because it was trained by an AI that was mimicking humans who were rating an AI that was mimicking humans who were pretending to be a better version of an AI that was trained on human writing.\n>\n> This circuitous technique is called “reinforcement learning from human feedback,” or RLHF, and it’s so effective that it’s worth pausing to fully register what it doesn’t do. When annotators teach a model to be accurate, for example, the model isn’t learning to check answers against logic or external sources or about what accuracy as a concept even is. The model is still a text-prediction machine mimicking patterns in human writing, but now its training corpus has been supplemented with bespoke examples, and the model has been weighted to favor them. Maybe this results in the model extracting patterns from the part of its linguistic map labeled as accurate and producing text that happens to align with the truth, but it can also result in it mimicking the confident style and expert jargon of the accurate text while writing things that are totally wrong. There is no guarantee that the text the labelers marked as accurate is in fact accurate, and when it is, there is no guarantee that the model learns the right patterns from it.\n\nMakes sense, and it's so very important to recognize this! We, humans, like to anthropomorphize things, and doubly so for LLMs since they can come across so... genuinely human.\n\nGenerating training data for AIs though appears... distinctly not-so-fun, mainly because it is so alien. Indeed, you are training an _excessively dumb_ machine:\n\n> It is in part a product of the way machine-learning systems learn. Where a human would get the concept of “shirt” with a few examples, machine-learning programs need thousands, and they need to be categorized with perfect consistency yet varied enough (polo shirts, shirts being worn outdoors, shirts hanging on a rack) that the very literal system can handle the diversity of the real world.\n> [...]\n> Instruction writers must come up with rules that will get humans to categorize the world with perfect consistency. To do so, they often create categories no human would use. A human asked to tag all the shirts in a photo probably wouldn’t tag the reflection of a shirt in a mirror because they would know it is a reflection and not real. But to the AI, which has no understanding of the world, it’s all just pixels and the two are perfectly identical. Fed a dataset with some shirts labeled and other (reflected) shirts unlabeled, the model won’t work. So the engineer goes back to the vendor with an update: DO label reflections of shirts. Soon, you have a 43-page guide descending into red all-caps.\n\nI fear though that before this era is over, most of us will have a \"job\" like this one, if indeed any at all.\n",
				"date_published": "2023-06-30T00:37:48+02:00",
				"url": "https://blog.gaborkozar.me/2023/06/30/inside-the-ai.html",
				"tags": ["technology","AI"]
			},
			{
				"id": "http://shdnx.micro.blog/2023/06/29/tech-erosion-the.html",
				"title": "Tech Erosion: the effect of technology (and AI) on our lives",
				"content_html": "<p>StillDrinking has a lot of great essays. He has a way with words that makes reading his articles both entertaining and illuminating at the same time &ndash; a powerful combination.</p>\n<p>Anyway, their essay on AI and ChatGPT, and how the world we have built will continue manages to be human-hostile in many ways in spite of (and indeed, in part <strong>because of</strong>) technology:</p>\n<h2 id=\"tech-erosionhttpswwwstilldrinkingorgtech-erosion\"><a href=\"https://www.stilldrinking.org/tech-erosion\">Tech Erosion</a></h2>\n<blockquote>\n<p>People are already losing their jobs. It’s not only the artists, whom nobody cares about until they’re gone, it’s copyeditors and clerks and designers. And just like self-checkouts and airport entry surveys, the humans are replaced by something a little bit worse. But it’s cheaper, and novelty often obscures indignity long enough for it to entrench, and we all accept that everything is a little bit slower, a little bit less trustworthy, and everything has a little more friction to grind us down over each day. The replacement bots could be honed into better tools, but who will bother once they’re accepted? Market trends always converge on giving us as little as possible.</p>\n</blockquote>\n<p>I&rsquo;d also be amiss if I didn&rsquo;t highlight this crucial insight into our collective fears of AIs:</p>\n<blockquote>\n<p>The terror of building a super artificial intelligence is not due to having something super intelligent hanging around, it is the terror of having something super intelligent that acts like a human. Because if we manage to build something technologically superior to us that also acts like us, it will do what technologically superior humans always do to their neighbors.</p>\n</blockquote>\n<p>Perhaps there are things that we, humanity as a whole, should just decide that we should not build &ndash; not because we cannot or because it would be evil, but because we are not sure it&rsquo;s a net positive as a whole. Of course, if we <em>were</em> able to choose so, we probably would have less to be concerned about already, given that we&rsquo;d clearly have a mechanism for informed, preventive, and collective action.</p>\n",
				"content_text": "StillDrinking has a lot of great essays. He has a way with words that makes reading his articles both entertaining and illuminating at the same time -- a powerful combination.\n\nAnyway, their essay on AI and ChatGPT, and how the world we have built will continue manages to be human-hostile in many ways in spite of (and indeed, in part **because of**) technology:\n\n## [Tech Erosion](https://www.stilldrinking.org/tech-erosion)\n\n> People are already losing their jobs. It’s not only the artists, whom nobody cares about until they’re gone, it’s copyeditors and clerks and designers. And just like self-checkouts and airport entry surveys, the humans are replaced by something a little bit worse. But it’s cheaper, and novelty often obscures indignity long enough for it to entrench, and we all accept that everything is a little bit slower, a little bit less trustworthy, and everything has a little more friction to grind us down over each day. The replacement bots could be honed into better tools, but who will bother once they’re accepted? Market trends always converge on giving us as little as possible.\n\nI'd also be amiss if I didn't highlight this crucial insight into our collective fears of AIs:\n> The terror of building a super artificial intelligence is not due to having something super intelligent hanging around, it is the terror of having something super intelligent that acts like a human. Because if we manage to build something technologically superior to us that also acts like us, it will do what technologically superior humans always do to their neighbors.\n\nPerhaps there are things that we, humanity as a whole, should just decide that we should not build -- not because we cannot or because it would be evil, but because we are not sure it's a net positive as a whole. Of course, if we _were_ able to choose so, we probably would have less to be concerned about already, given that we'd clearly have a mechanism for informed, preventive, and collective action.\n",
				"date_published": "2023-06-29T23:02:19+02:00",
				"url": "https://blog.gaborkozar.me/2023/06/29/tech-erosion-the.html",
				"tags": ["technology","AI"]
			}
	]
}
